{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) CounterVectorizer 을 사용하였을때, doc['text']의 500번째 문서와 가장 유사한 문서 추출 (Cosine Similarity 기반)\n",
    "## 2) TfidfVectorizer을 사용하였을때, doc['text']의 500번째 문서와 가장 유사한 문서 추출 (Cosine Similarity 기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.read_csv('./tfidf_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>musicians tackle red tape musicians groups tac...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u2 desire number u2 won prestigious grammy awa...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rocker doherty stage fight rock singer pete do...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snicket tops box office chart film adaptation ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ocean raids box office ocean crime caper seque...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>norway upholds napster ruling norwegian studen...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>warning windows word files writing microsoft w...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>fast lifts record books high speed lifts world...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>nintendo adds media playing ds nintendo releas...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>fast moving phone viruses appear security firm...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       category\n",
       "0     musicians tackle red tape musicians groups tac...  entertainment\n",
       "1     u2 desire number u2 won prestigious grammy awa...  entertainment\n",
       "2     rocker doherty stage fight rock singer pete do...  entertainment\n",
       "3     snicket tops box office chart film adaptation ...  entertainment\n",
       "4     ocean raids box office ocean crime caper seque...  entertainment\n",
       "...                                                 ...            ...\n",
       "2220  norway upholds napster ruling norwegian studen...           tech\n",
       "2221  warning windows word files writing microsoft w...           tech\n",
       "2222  fast lifts record books high speed lifts world...           tech\n",
       "2223  nintendo adds media playing ds nintendo releas...           tech\n",
       "2224  fast moving phone viruses appear security firm...           tech\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_doc(index, bow, corpus):\n",
    "    idx = (-cosine_similarity(bow[index], bow)[0]).argsort()[1]\n",
    "    return corpus[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    pattern = re.compile('[\\u3131-\\u3163\\uac00-\\ud7a3]+')\n",
    "    text = re.sub(pattern = pattern,repl = ' ',string = text) #한글삭제(인코딩 오류인지,,, 짙이런 단어가 생기길래 삭제,,)\n",
    "    \n",
    "    pattern = '(\\[a-zA-Z0-9\\_.+-\\]+@\\[a-zA-Z0-9]+.\\[a-zA-Z0-9-.\\]+)' # email제거\n",
    "    text = re.sub(pattern = pattern,repl = ' ',string = text)\n",
    "    \n",
    "    pattern = re.compile(r'([^\\w]?\\d+\\.?\\,?\\)?\\d*)+') # 숫자 제거\n",
    "    text = re.sub(pattern = pattern,repl = ' ',string = text)\n",
    "    \n",
    "    pattern = '<[^>]*>' # html 태그 제거\n",
    "    text = re.sub(pattern = pattern,repl = ' ',string = text)\n",
    "    \n",
    "    pattern = '[\\r|\\n]' # \\r,\\n 제거\n",
    "    text = re.sub(pattern = pattern,repl = ' ',string = text)\n",
    "    \n",
    "    pattern =  '[^\\w\\s]' # 특수기호 제거\n",
    "    text = re.sub(pattern = pattern,repl = ' ',string = text)\n",
    "    \n",
    "    pattern = re.compile(r'\\s+')  #  이중 space 제거\n",
    "    text = re.sub(pattern = pattern,repl = ' ',string = text)\n",
    "\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       musicians tackle red tape musicians groups tac...\n",
       "1       u desire number u won prestigious grammy award...\n",
       "2       rocker doherty stage fight rock singer pete do...\n",
       "3       snicket tops box office chart film adaptation ...\n",
       "4       ocean raids box office ocean crime caper seque...\n",
       "                              ...                        \n",
       "2220    norway upholds napster ruling norwegian studen...\n",
       "2221    warning windows word files writing microsoft w...\n",
       "2222    fast lifts record books high speed lifts world...\n",
       "2223    nintendo adds media playing ds nintendo releas...\n",
       "2224    fast moving phone viruses appear security firm...\n",
       "Name: text, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = doc['text'].apply(clean_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [musicians, tackle, red, tape, musicians, grou...\n",
       "1       [u, desire, number, u, won, prestigious, gramm...\n",
       "2       [rocker, doherty, stage, fight, rock, singer, ...\n",
       "3       [snicket, tops, box, office, chart, film, adap...\n",
       "4       [ocean, raids, box, office, ocean, crime, cape...\n",
       "                              ...                        \n",
       "2220    [norway, upholds, napster, ruling, norwegian, ...\n",
       "2221    [warning, windows, word, files, writing, micro...\n",
       "2222    [fast, lifts, record, books, high, speed, lift...\n",
       "2223    [nintendo, adds, media, playing, ds, nintendo,...\n",
       "2224    [fast, moving, phone, viruses, appear, securit...\n",
       "Name: text, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize_result = data.apply(word_tokenize)\n",
    "word_tokenize_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [(musicians, NNS), (tackle, VBP), (red, JJ), (...\n",
      "1       [(u, JJ), (desire, NN), (number, NN), (u, JJ),...\n",
      "2       [(rocker, NN), (doherty, NN), (stage, NN), (fi...\n",
      "3       [(snicket, NN), (tops, NNS), (box, JJ), (offic...\n",
      "4       [(ocean, JJ), (raids, NNS), (box, NN), (office...\n",
      "                              ...                        \n",
      "2220    [(norway, RB), (upholds, JJ), (napster, RB), (...\n",
      "2221    [(warning, VBG), (windows, NNS), (word, NN), (...\n",
      "2222    [(fast, JJ), (lifts, NN), (record, NN), (books...\n",
      "2223    [(nintendo, NN), (adds, VBZ), (media, NNS), (p...\n",
      "2224    [(fast, RB), (moving, VBG), (phone, NN), (viru...\n",
      "Name: text, Length: 2225, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pos_result = word_tokenize_result.apply(nltk.pos_tag)\n",
    "print(pos_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 명사만 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_nouns(token_pos):\n",
    "    nouns = []\n",
    "    for word, pos in token_pos:\n",
    "        if 'NN' in pos:\n",
    "            nouns.append(word)\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [musicians, tape, musicians, groups, regulatio...\n",
      "1       [desire, number, grammy, awards, status, world...\n",
      "2       [rocker, doherty, stage, fight, rock, singer, ...\n",
      "3       [snicket, tops, office, chart, film, adaptatio...\n",
      "4       [raids, box, office, ocean, crime, caper, sequ...\n",
      "                              ...                        \n",
      "2220    [student, mp, files, compensation, country, co...\n",
      "2221    [windows, word, word, document, business, docu...\n",
      "2222    [lifts, record, books, speed, lifts, world, bu...\n",
      "2223    [nintendo, media, ds, handheld, play, music, v...\n",
      "2224    [phone, viruses, security, firms, phone, virus...\n",
      "Name: text, Length: 2225, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nouns = pos_result.apply(only_nouns)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 리스트에 문서 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = []\n",
    "for i in range(len(nouns)):\n",
    "    total_docs.append(' '.join(nouns[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) CounterVectorizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1,stop_words = 'english') #불용어 제거해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = vectorizer.fit_transform(total_docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★CounterVectorizer 을 사용하였을때, doc[text]의 500번째 문서와 가장 유사한 문서★\n",
      "\n",
      "germany nears 1990 jobless level german unemployment rose 11th consecutive month december making average jobless total highest reunification seasonally adjusted jobless total rose higher expected 17 4 483 million bundesbank allowing changes calculating statistics average people work highest 1990 rate bad weather sluggish economy blamed rise increase primarily onstart winter labour office chief frank juergen weise unadjusted figures showed unemployment rose 206 900 4 64 million sectors construction laying workers amid bad weather years stagnation german economy came 2004 upturn strong boost labour market weise added news rise came welfare reforms came force expected unemployment swell coming months hartz iv changes previous tier system benefits support long term unemployed replaced flat rate payout turn means people classified looking work driving official figures higher prepared nasty figure january million unemployed non seasonally adjusted basis warned hvb group economist andreas rees add numbers subside remain near 2004 level 4 4 million jobless expect strong lasting turnaround 2006 german economy wolfgang clement 2010 hartz iv reforms help cut average jobless rate added biggest economy weak create work struggles shake years economic stagnation recent months adam opel german arm carmaker motors retailer karstadtquelle slashed jobs\n"
     ]
    }
   ],
   "source": [
    "print('★CounterVectorizer 을 사용하였을때, doc[''text'']의 500번째 문서와 가장 유사한 문서★\\n')\n",
    "print(find_most_similar_doc(500, bow, doc['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer(min_df=1, stop_words = 'english')#불용어 제거해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_m = tfidfvect.fit_transform(total_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★TfidfVectorizer 을 사용하였을때, doc[text]의 500번째 문서와 가장 유사한 문서★\n",
      "\n",
      "brazil jobless rate hits low brazil unemployment rate fell lowest level years december according government brazilian institute geography statistics ibge fell 9 6 december 10 6 november 10 9 december 2003 ibge average monthly salaries grew 1 9 december 2004 december 2003 average monthly wages fell 1 december 895 4 reais 332 179 3 november tuesday represent unemployment rate fallen single digit measurement rules introduced 2001 unemployment rate falling gradually april 2004 reached peak 13 1 jobless rate average 2004 11 5 3 2003 ibge improvement attributed country economic growth economy registering growth 5 2004 government economy grow 4 president luiz inacio lula da silva promised reduce unemployment elected years ago analysts unemployment increase data favourable jobs temporary christmas holiday season slightly higher joblessness february julio hegedus economist lopes filho associates consultancy rio de janeir reuters agency despite leftist background president lula pursued surprisingly conservative economic policy arguing order meet social promises government needs reach sustained economic growth unemployment rate measured main metropolitan areas brazil sao paolo rio de janeiro belo horizonte recife salvador porto alegre population concentrated\n"
     ]
    }
   ],
   "source": [
    "print('★TfidfVectorizer 을 사용하였을때, doc[''text'']의 500번째 문서와 가장 유사한 문서★\\n')\n",
    "print(find_most_similar_doc(500, tfidf_m, doc['text']))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
